{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px \n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd \n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "csv_path = cwd + \"/tmp/benchmarks/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "fig = px.line(df, x='Set size', y='cache-misses', title=\"Cache misses relative to amount of sequences compared <b>Repo : \" + df['Repo Version'].iloc[0] + \"</b>\")\n",
    "fig.update_layout(yaxis_title='cache misses (%)', xaxis_title='Number of unique sequences compared')\n",
    "fig.show()\n",
    "\n",
    "fig = px.line(df, x='Set size', y='elapsed time', title=\"Cache misses relative to amount of sequences compared <b>Repo : \" + df['Repo Version'].iloc[0] + \"</b>\")\n",
    "fig.update_layout(yaxis_title='cache misses (%)', xaxis_title='Number of unique sequences compared')\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following section analysises the relation of file size to input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = []\n",
    "threshold = []\n",
    "min_count = []\n",
    "max_depth = []\n",
    "size = []\n",
    "\n",
    "directory = \"data/benchmarking/parameter_test\"\n",
    "\n",
    "for filename in os.listdir(\"data/benchmarking/parameter_test\"):\n",
    "    f = os.path.join(directory, filename)\n",
    "    file_stats = os.stat(f)\n",
    "    parameters = filename.split(\"_\")\n",
    "    sequence.append(parameters[1])\n",
    "    threshold.append(float(parameters[2]))\n",
    "    min_count.append(int(parameters[3]))\n",
    "    max_depth.append(int(parameters[4].split(\".\")[0]))\n",
    "    size.append(file_stats.st_size)\n",
    "\n",
    "data = {\n",
    "    \"sequence\" : sequence, \n",
    "    \"threshold\" : threshold,\n",
    "    \"min_count\" : min_count,\n",
    "    \"max_depth\" : max_depth,\n",
    "    \"size\" : size\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_size_threshold'] = df.groupby(['threshold'])['size'].transform('mean')\n",
    "df['avg_size_min_count'] = df.groupby(['min_count'])['size'].transform('mean')\n",
    "df['avg_size_max_depth'] = df.groupby(['max_depth'])['size'].transform('mean')\n",
    "\n",
    "df_threshold = df[['threshold', 'avg_size_threshold']]\n",
    "df_threshold.drop_duplicates(inplace=True)\n",
    "df_threshold.sort_values('threshold', inplace=True)\n",
    "\n",
    "df_min_count = df[['min_count', 'avg_size_min_count']]\n",
    "df_min_count.drop_duplicates(inplace=True)\n",
    "df_min_count.sort_values('min_count', inplace=True)\n",
    "\n",
    "df_max_depth = df[['max_depth', 'avg_size_max_depth']]\n",
    "df_max_depth.drop_duplicates(inplace=True)\n",
    "df_max_depth.sort_values('max_depth', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df_threshold['threshold'], y=df_threshold['avg_size_threshold'], name='threshold'))\n",
    "fig.add_trace(go.Scatter(x=df_min_count['min_count'], y=df_min_count['avg_size_min_count'], name='min_count'))\n",
    "fig.add_trace(go.Scatter(x=df_max_depth['max_depth'], y=df_max_depth['avg_size_max_depth'], name='max_depth'))\n",
    "\n",
    "fig.update_layout(yaxis_title='Size (Bytes)', xaxis_title='Parameter', title='File size change in relation to parameter tuning')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Visualizing Benchmarking on Human Dataset</b>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize time elapsed compared to amount of VLMCs compared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('csv_results/03_15_11_44.csv')\n",
    "df_pst = df[df.implementation=='PstClassifierSeqan']\n",
    "df_sv = df[df.implementation=='sorted-vector']\n",
    "fig = go.Figure()\n",
    "\n",
    "for vlmc_size in ['small', 'medium', 'large']:\n",
    "  fig.add_trace(go.Scatter(x=df_sv[df_sv.vlmc_size==vlmc_size]['set_size'], y=df_sv[df_sv.vlmc_size==vlmc_size]['elapsed_time'], name=\"sorted-vector \" + vlmc_size))\n",
    "  fig.add_trace(go.Scatter(x=df_pst[df_pst.vlmc_size==vlmc_size]['set_size'], y=df_pst[df_pst.vlmc_size==vlmc_size]['elapsed_time'], name=\"PstClassifierSeqan \" + vlmc_size, marker_symbol='x'))\n",
    "\n",
    "fig.update_layout(title=\"Elapsed time compared to amount of VLMCs compared\", yaxis_title=\"Elapsed time (sec)\", xaxis_title=\"Size of directory of VLMCs\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing cache-misses in relation to amount of VLMCs compared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('csv_results/03_15_11_44.csv')\n",
    "df_pst = df[df.implementation=='PstClassifierSeqan']\n",
    "df_sv = df[df.implementation=='sorted-vector']\n",
    "fig = go.Figure()\n",
    "\n",
    "for vlmc_size in ['small', 'medium', 'large']:\n",
    "  fig.add_trace(go.Scatter(x=df_sv[df_sv.vlmc_size==vlmc_size]['set_size'], y=df_sv[df_sv.vlmc_size==vlmc_size]['cache_misses'], name=\"sorted-vector \" + vlmc_size))\n",
    "  fig.add_trace(go.Scatter(x=df_pst[df_pst.vlmc_size==vlmc_size]['set_size'], y=df_pst[df_pst.vlmc_size==vlmc_size]['cache_misses'], name=\"PstClassifierSeqan \" + vlmc_size, marker_symbol='x'))\n",
    "\n",
    "fig.update_layout(title=\"Cache-misses compared to amount of VLMCs compared\", yaxis_title=\"Cache-misses (%)\", xaxis_title=\"Size of directory of VLMCs\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing degree of parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('csv_results/parallelization_human_03_15_13_45.csv')\n",
    "df_small = df[df.vlmc_size==\"small\"]\n",
    "\n",
    "fig = px.line(df, x='nr_cores_used', y='elapsed_time', color='vlmc_size')\n",
    "\n",
    "fig.update_layout(title=\"Elapsed time compared to amount of cores used\", yaxis_title=\"Elapsed time (sec)\", xaxis_title=\"Amount of cores used\")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "fig = px.line(df, x='nr_cores_used', y='task_clock', color='vlmc_size')\n",
    "\n",
    "fig.update_layout(title=\"Degree of parallelization compared to amount of cores used\", yaxis_title=\"Degree of parallelization\", xaxis_title=\"Amount of cores used\")\n",
    "\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Visualizing Benchmarking on E-coli Dataset</b>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize time elapsed compared to amount of VLMCs compared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pst = df = pd.read_csv('csv_results/ecoli_03_16_09_44.csv')\n",
    "df_sv = df = pd.read_csv('csv_results/ecoli_03_16_09_39.csv')\n",
    "fig = go.Figure()\n",
    "\n",
    "for vlmc_size in ['small', 'medium', 'large']:\n",
    "  fig.add_trace(go.Scatter(x=df_sv[df_sv.vlmc_size==vlmc_size]['set_size'], y=df_sv[df_sv.vlmc_size==vlmc_size]['elapsed_time'], name=\"sorted-vector \" + vlmc_size))\n",
    "  fig.add_trace(go.Scatter(x=df_pst[df_pst.vlmc_size==vlmc_size]['set_size'], y=df_pst[df_pst.vlmc_size==vlmc_size]['elapsed_time'], name=\"PstClassifierSeqan \" + vlmc_size, marker_symbol='x'))\n",
    "\n",
    "fig.update_layout(title=\"Elapsed time compared to amount of VLMCs compared\", yaxis_title=\"Elapsed time (sec)\", xaxis_title=\"Size of directory of VLMCs\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Comparison of vlmc container </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sv = pd.read_csv('csv_results/sorted-vector_human_03_20_12_09.csv')\n",
    "df_hm = pd.read_csv('csv_results/hashmap_human_03_20_12_10.csv')\n",
    "df_co = pd.read_csv('csv_results/combo_human_03_20_12_10.csv')\n",
    "\n",
    "fig = go.Figure()\n",
    "vlmc_size = 'small'\n",
    "fig.add_trace(go.Scatter(x=df_sv[df_sv.vlmc_size==vlmc_size]['set_size'], y=df_sv[df_sv.vlmc_size==vlmc_size]['elapsed_time'], name=\"sorted-vector \" + vlmc_size))\n",
    "fig.add_trace(go.Scatter(x=df_hm[df_hm.vlmc_size==vlmc_size]['set_size'], y=df_hm[df_hm.vlmc_size==vlmc_size]['elapsed_time'], name=\"hashmap \" + vlmc_size))\n",
    "fig.add_trace(go.Scatter(x=df_co[df_co.vlmc_size==vlmc_size]['set_size'], y=df_co[df_co.vlmc_size==vlmc_size]['elapsed_time'], name=\"combo \" + vlmc_size))\n",
    "fig.update_layout(title=\"Elapsed time compared to amount of VLMCs compared for different vlmc containers (dataset human small)\", yaxis_title=\"Elapsed time (sec)\", xaxis_title=\"Size of directory of VLMCs\")\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure()\n",
    "vlmc_size = 'medium'\n",
    "fig.add_trace(go.Scatter(x=df_sv[df_sv.vlmc_size==vlmc_size]['set_size'], y=df_sv[df_sv.vlmc_size==vlmc_size]['elapsed_time'], name=\"sorted-vector \" + vlmc_size))\n",
    "fig.add_trace(go.Scatter(x=df_hm[df_hm.vlmc_size==vlmc_size]['set_size'], y=df_hm[df_hm.vlmc_size==vlmc_size]['elapsed_time'], name=\"hashmap \" + vlmc_size))\n",
    "fig.add_trace(go.Scatter(x=df_co[df_co.vlmc_size==vlmc_size]['set_size'], y=df_co[df_co.vlmc_size==vlmc_size]['elapsed_time'], name=\"combo \" + vlmc_size))\n",
    "fig.update_layout(title=\"Elapsed time compared to amount of VLMCs compared for different vlmc containers (dataset human medium)\", yaxis_title=\"Elapsed time (sec)\", xaxis_title=\"Size of directory of VLMCs\")\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure()\n",
    "vlmc_size = 'large'\n",
    "fig.add_trace(go.Scatter(x=df_sv[df_sv.vlmc_size==vlmc_size]['set_size'], y=df_sv[df_sv.vlmc_size==vlmc_size]['elapsed_time'], name=\"sorted-vector \" + vlmc_size))\n",
    "fig.add_trace(go.Scatter(x=df_hm[df_hm.vlmc_size==vlmc_size]['set_size'], y=df_hm[df_hm.vlmc_size==vlmc_size]['elapsed_time'], name=\"hashmap \" + vlmc_size))\n",
    "fig.add_trace(go.Scatter(x=df_co[df_co.vlmc_size==vlmc_size]['set_size'], y=df_co[df_co.vlmc_size==vlmc_size]['elapsed_time'], name=\"combo \" + vlmc_size))\n",
    "fig.update_layout(title=\"Elapsed time compared to amount of VLMCs compared for different vlmc containers (dataset human large)\", yaxis_title=\"Elapsed time (sec)\", xaxis_title=\"Size of directory of VLMCs\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sv = pd.read_csv('csv_results/sorted-vector_human_03_20_12_09.csv')\n",
    "df_hm = pd.read_csv('csv_results/hashmap_human_03_20_12_10.csv')\n",
    "df_co = pd.read_csv('csv_results/combo_human_03_20_12_10.csv')\n",
    "\n",
    "fig = go.Figure()\n",
    "vlmc_size = 'small'\n",
    "fig.add_trace(go.Scatter(x=df_sv[df_sv.vlmc_size==vlmc_size]['set_size'], y=df_sv[df_sv.vlmc_size==vlmc_size]['cache_misses'], name=\"sorted-vector \" + vlmc_size))\n",
    "fig.add_trace(go.Scatter(x=df_hm[df_hm.vlmc_size==vlmc_size]['set_size'], y=df_hm[df_hm.vlmc_size==vlmc_size]['cache_misses'], name=\"hashmap \" + vlmc_size))\n",
    "fig.add_trace(go.Scatter(x=df_co[df_co.vlmc_size==vlmc_size]['set_size'], y=df_co[df_co.vlmc_size==vlmc_size]['cache_misses'], name=\"combo \" + vlmc_size))\n",
    "fig.update_layout(title=\"Elapsed time compared to amount of VLMCs compared for different vlmc containers (dataset human small)\", yaxis_title=\"Elapsed time (sec)\", xaxis_title=\"Size of directory of VLMCs\")\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure()\n",
    "vlmc_size = 'medium'\n",
    "fig.add_trace(go.Scatter(x=df_sv[df_sv.vlmc_size==vlmc_size]['set_size'], y=df_sv[df_sv.vlmc_size==vlmc_size]['cache_misses'], name=\"sorted-vector \" + vlmc_size))\n",
    "fig.add_trace(go.Scatter(x=df_hm[df_hm.vlmc_size==vlmc_size]['set_size'], y=df_hm[df_hm.vlmc_size==vlmc_size]['cache_misses'], name=\"hashmap \" + vlmc_size))\n",
    "fig.add_trace(go.Scatter(x=df_co[df_co.vlmc_size==vlmc_size]['set_size'], y=df_co[df_co.vlmc_size==vlmc_size]['cache_misses'], name=\"combo \" + vlmc_size))\n",
    "fig.update_layout(title=\"Elapsed time compared to amount of VLMCs compared for different vlmc containers (dataset human medium)\", yaxis_title=\"Elapsed time (sec)\", xaxis_title=\"Size of directory of VLMCs\")\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure()\n",
    "vlmc_size = 'large'\n",
    "fig.add_trace(go.Scatter(x=df_sv[df_sv.vlmc_size==vlmc_size]['set_size'], y=df_sv[df_sv.vlmc_size==vlmc_size]['cache_misses'], name=\"sorted-vector \" + vlmc_size))\n",
    "fig.add_trace(go.Scatter(x=df_hm[df_hm.vlmc_size==vlmc_size]['set_size'], y=df_hm[df_hm.vlmc_size==vlmc_size]['cache_misses'], name=\"hashmap \" + vlmc_size))\n",
    "fig.add_trace(go.Scatter(x=df_co[df_co.vlmc_size==vlmc_size]['set_size'], y=df_co[df_co.vlmc_size==vlmc_size]['cache_misses'], name=\"combo \" + vlmc_size))\n",
    "fig.update_layout(title=\"Elapsed time compared to amount of VLMCs compared for different vlmc containers (dataset human large)\", yaxis_title=\"Elapsed time (sec)\", xaxis_title=\"Size of directory of VLMCs\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sv = pd.read_csv('csv_results/sorted-vector_ecoli_03_20_12_30.csv')\n",
    "df_hm = pd.read_csv('csv_results/hashmap_ecoli_03_20_12_32.csv')\n",
    "df_co = pd.read_csv('csv_results/combo_ecoli_03_20_12_51.csv')\n",
    "\n",
    "fig = go.Figure()\n",
    "vlmc_size = 'small'\n",
    "fig.add_trace(go.Scatter(x=df_sv[df_sv.vlmc_size==vlmc_size]['set_size'], y=df_sv[df_sv.vlmc_size==vlmc_size]['elapsed_time'], name=\"sorted-vector \" + vlmc_size))\n",
    "fig.add_trace(go.Scatter(x=df_hm[df_hm.vlmc_size==vlmc_size]['set_size'], y=df_hm[df_hm.vlmc_size==vlmc_size]['elapsed_time'], name=\"hashmap \" + vlmc_size))\n",
    "fig.add_trace(go.Scatter(x=df_co[df_co.vlmc_size==vlmc_size]['set_size'], y=df_co[df_co.vlmc_size==vlmc_size]['elapsed_time'], name=\"combo \" + vlmc_size))\n",
    "fig.update_layout(title=\"Elapsed time compared to amount of VLMCs compared for different vlmc containers (dataset human small)\", yaxis_title=\"Elapsed time (sec)\", xaxis_title=\"Size of directory of VLMCs\")\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure()\n",
    "vlmc_size = 'medium'\n",
    "fig.add_trace(go.Scatter(x=df_sv[df_sv.vlmc_size==vlmc_size]['set_size'], y=df_sv[df_sv.vlmc_size==vlmc_size]['elapsed_time'], name=\"sorted-vector \" + vlmc_size))\n",
    "fig.add_trace(go.Scatter(x=df_hm[df_hm.vlmc_size==vlmc_size]['set_size'], y=df_hm[df_hm.vlmc_size==vlmc_size]['elapsed_time'], name=\"hashmap \" + vlmc_size))\n",
    "fig.add_trace(go.Scatter(x=df_co[df_co.vlmc_size==vlmc_size]['set_size'], y=df_co[df_co.vlmc_size==vlmc_size]['elapsed_time'], name=\"combo \" + vlmc_size))\n",
    "fig.update_layout(title=\"Elapsed time compared to amount of VLMCs compared for different vlmc containers (dataset human medium)\", yaxis_title=\"Elapsed time (sec)\", xaxis_title=\"Size of directory of VLMCs\")\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure()\n",
    "vlmc_size = 'large'\n",
    "fig.add_trace(go.Scatter(x=df_sv[df_sv.vlmc_size==vlmc_size]['set_size'], y=df_sv[df_sv.vlmc_size==vlmc_size]['elapsed_time'], name=\"sorted-vector \" + vlmc_size))\n",
    "fig.add_trace(go.Scatter(x=df_hm[df_hm.vlmc_size==vlmc_size]['set_size'], y=df_hm[df_hm.vlmc_size==vlmc_size]['elapsed_time'], name=\"hashmap \" + vlmc_size))\n",
    "fig.add_trace(go.Scatter(x=df_co[df_co.vlmc_size==vlmc_size]['set_size'], y=df_co[df_co.vlmc_size==vlmc_size]['elapsed_time'], name=\"combo \" + vlmc_size))\n",
    "fig.update_layout(title=\"Elapsed time compared to amount of VLMCs compared for different vlmc containers (dataset human large)\", yaxis_title=\"Elapsed time (sec)\", xaxis_title=\"Size of directory of VLMCs\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sv = pd.read_csv('csv_results/sorted-vector_ecoli_03_20_12_30.csv')\n",
    "df_hm = pd.read_csv('csv_results/hashmap_ecoli_03_20_12_32.csv')\n",
    "df_co = pd.read_csv('csv_results/combo_ecoli_03_20_12_51.csv')\n",
    "\n",
    "fig = go.Figure()\n",
    "vlmc_size = 'small'\n",
    "fig.add_trace(go.Scatter(x=df_sv[df_sv.vlmc_size==vlmc_size]['set_size'], y=df_sv[df_sv.vlmc_size==vlmc_size]['cache_misses'], name=\"sorted-vector \" + vlmc_size))\n",
    "fig.add_trace(go.Scatter(x=df_hm[df_hm.vlmc_size==vlmc_size]['set_size'], y=df_hm[df_hm.vlmc_size==vlmc_size]['cache_misses'], name=\"hashmap \" + vlmc_size))\n",
    "fig.add_trace(go.Scatter(x=df_co[df_co.vlmc_size==vlmc_size]['set_size'], y=df_co[df_co.vlmc_size==vlmc_size]['cache_misses'], name=\"combo \" + vlmc_size))\n",
    "fig.update_layout(title=\"Elapsed time compared to amount of VLMCs compared for different vlmc containers (dataset human small)\", yaxis_title=\"Elapsed time (sec)\", xaxis_title=\"Size of directory of VLMCs\")\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure()\n",
    "vlmc_size = 'medium'\n",
    "fig.add_trace(go.Scatter(x=df_sv[df_sv.vlmc_size==vlmc_size]['set_size'], y=df_sv[df_sv.vlmc_size==vlmc_size]['cache_misses'], name=\"sorted-vector \" + vlmc_size))\n",
    "fig.add_trace(go.Scatter(x=df_hm[df_hm.vlmc_size==vlmc_size]['set_size'], y=df_hm[df_hm.vlmc_size==vlmc_size]['cache_misses'], name=\"hashmap \" + vlmc_size))\n",
    "fig.add_trace(go.Scatter(x=df_co[df_co.vlmc_size==vlmc_size]['set_size'], y=df_co[df_co.vlmc_size==vlmc_size]['cache_misses'], name=\"combo \" + vlmc_size))\n",
    "fig.update_layout(title=\"Elapsed time compared to amount of VLMCs compared for different vlmc containers (dataset human medium)\", yaxis_title=\"Elapsed time (sec)\", xaxis_title=\"Size of directory of VLMCs\")\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure()\n",
    "vlmc_size = 'large'\n",
    "fig.add_trace(go.Scatter(x=df_sv[df_sv.vlmc_size==vlmc_size]['set_size'], y=df_sv[df_sv.vlmc_size==vlmc_size]['cache_misses'], name=\"sorted-vector \" + vlmc_size))\n",
    "fig.add_trace(go.Scatter(x=df_hm[df_hm.vlmc_size==vlmc_size]['set_size'], y=df_hm[df_hm.vlmc_size==vlmc_size]['cache_misses'], name=\"hashmap \" + vlmc_size))\n",
    "fig.add_trace(go.Scatter(x=df_co[df_co.vlmc_size==vlmc_size]['set_size'], y=df_co[df_co.vlmc_size==vlmc_size]['cache_misses'], name=\"combo \" + vlmc_size))\n",
    "fig.update_layout(title=\"Elapsed time compared to amount of VLMCs compared for different vlmc containers (dataset human large)\", yaxis_title=\"Elapsed time (sec)\", xaxis_title=\"Size of directory of VLMCs\")\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Parameter Sweep for combo container </b>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('csv_results/parameter_sweep_human_03_20_10_33.csv')\n",
    "df['mean_elapsed_time'] = df.groupby(['vlmc_size', 'combo_init_size'])['elapsed_time'].transform('mean')\n",
    "df.sort_values('combo_init_size', inplace=True)\n",
    "fig = px.line(df, x='combo_init_size', y='mean_elapsed_time', color='vlmc_size')\n",
    "\n",
    "fig.update_layout(title=\"Elapsed time with different initial sizes for index by value vector\", yaxis_title=\"Elapsed time (sec)\", xaxis_title=\"Initial size for index by value vector\")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "df.groupby('vlmc_size').mean_elapsed_time.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('csv_results/parameter_sweep_ecoli_03_20_10_40.csv')\n",
    "df['mean_elapsed_time'] = df.groupby(['vlmc_size', 'combo_init_size'])['elapsed_time'].transform('mean')\n",
    "df.sort_values('combo_init_size', inplace=True)\n",
    "fig = px.line(df, x='combo_init_size', y='mean_elapsed_time', color='vlmc_size')\n",
    "\n",
    "fig.update_layout(title=\"Elapsed time with different initial sizes for index by value vector\", yaxis_title=\"Elapsed time (sec)\", xaxis_title=\"Initial size for index by value vector\")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "df.groupby('vlmc_size').mean_elapsed_time.min()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Kmer distributions </b>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./tmp/human_VLMCs_kmer-distribution.txt\", sep=\",\", header=None)\n",
    "\n",
    "fig = px.histogram(df)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E-coli dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./tmp/small_test_kmer-distribution.txt\", sep=\",\", header=None)\n",
    "\n",
    "fig = px.histogram(df)\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "48d0a4ca29d602f526e1aa695dc41e454d4aef6a87f358e764b4e396349856d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
